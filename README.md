# Pensieve Project Fill Service

This project implements the `/api/project-fill` endpoint on Next.js (Edge Runtime). The service aggregates Bing search, lightweight HTML fetching, and LLM-based structured extraction, while optionally overlaying data from RootData.

## Key Features

- Compatible with the Vercel AI SDK and uses the OpenAI `gpt-4o-mini` model for structured extraction.
- Optional RootData API enrichment to override LLM fields with verified data.
- Combines Bing search with lightweight fetching to build structured context.
- Provides extensible utility functions including timeout protection, HTML cleanup, and URL validation.

## Environment Variables

- `OPENAI_API_KEY` (required)
- `BING_KEY` (required)
- `ROOTDATA_API_KEY` (optional)
- `HTML_EXCERPT` (optional, default `5000`)
- `DEFAULT_LIMIT` (optional, default `3`)

Configure these values via your Vercel/Next.js environment manager.

## Quick Start

```bash
npm install
npm run dev
```

The development server listens on `http://127.0.0.1:3000` by default.

## Self-Check Steps

1. **Start locally**
   ```bash
   npm i && npm run dev
   ```
2. **Health check**
   ```bash
   curl http://127.0.0.1:3000/api/project-fill
   ```
3. **Functional test**
   ```bash
   curl -X POST http://127.0.0.1:3000/api/project-fill \
     -H 'content-type: application/json' \
     -d '{"q":"Ethereum Foundation","limit":3}'
   ```

Expect the response object to include every schema field (values may be `null`) with `meta.is_autogenerated=true` and `meta.data_quality="mixed"`.

## Deployment Notes

- Deploy to Vercel or any platform that supports the Edge Runtime and provide the required environment variables.
- Extend `app/api/project-fill/route.ts` to integrate additional models or data sources.
